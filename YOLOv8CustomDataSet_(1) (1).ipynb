{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7YQplyFRtrgj"
   },
   "source": [
    "# Importing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tcCAACRFtnJn",
    "outputId": "61a5e29b-8df5-43cb-f5bd-3e3ca09615cb"
   },
   "outputs": [],
   "source": [
    "# Pip install ultralytics and dependencies and check software and hardware.\n",
    "%pip install ultralytics -q\n",
    "import ultralytics\n",
    "import os\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GT--dLRltuQX"
   },
   "outputs": [],
   "source": [
    "VIDEOS_DIR = 'sample.mp4'\n",
    "video_path='sample.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rcONT8KJt0WC"
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jFSx97k4t0xv"
   },
   "outputs": [],
   "source": [
    "ret, frame = cap.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1qRG0Z_GuXpi"
   },
   "outputs": [],
   "source": [
    "MODEL_DIR = 'license_plate_detector.pt'\n",
    "model_path = 'license_plate_detector.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load YOLO model\n",
    "MODEL_PATH = \"license_plate_detector.pt\"  # Replace with your YOLO model path\n",
    "model = YOLO(MODEL_PATH)\n",
    "\n",
    "# Video input and output\n",
    "video_path = \"input_video.mp4\"  # Replace with your input video file path\n",
    "output_path = \"output_video.mp4\"  # Output video file path\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Check if the video is opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(f\"Error: Cannot open video {video_path}\")\n",
    "    exit()\n",
    "\n",
    "# Get video properties\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "# Define VideoWriter\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "# Detection threshold\n",
    "threshold = 0.5\n",
    "\n",
    "# Read and process video frames\n",
    "ret, frame = cap.read()\n",
    "while ret:\n",
    "    # Perform detection\n",
    "    results = model(frame)[0]\n",
    "\n",
    "    # Annotate detections on the frame\n",
    "    for result in results.boxes.data.tolist():\n",
    "        x1, y1, x2, y2, score, class_id = result\n",
    "        if score > threshold:\n",
    "            # Draw bounding box\n",
    "            cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 4)\n",
    "            # Add label\n",
    "            cv2.putText(frame, f\"{model.names[int(class_id)]} {score:.2f}\", (int(x1), int(y1) - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1.3, (0, 255, 0), 3, cv2.LINE_AA)\n",
    "\n",
    "    # Display frame using matplotlib\n",
    "    plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    # Write processed frame to output video\n",
    "    out.write(frame)\n",
    "\n",
    "    # Read the next frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "out.release()\n",
    "print(f\"Processed video saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load YOLO model\n",
    "model_path = \"license_plate_detector.pt\"\n",
    "model = YOLO(model_path)\n",
    "\n",
    "# Input and output video paths\n",
    "video_path = 'sample.mp4'\n",
    "output_path = 'sample_output.mp4'\n",
    "\n",
    "# Initialize video capture\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video.\")\n",
    "    exit()\n",
    "\n",
    "# Get video properties\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "# Define VideoWriter\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "# Detection threshold\n",
    "threshold = 0.5\n",
    "\n",
    "# Initialize frame counter for debugging\n",
    "frame_count = 0\n",
    "\n",
    "# Process video frames\n",
    "ret, frame = cap.read()\n",
    "while ret:\n",
    "    # Perform inference\n",
    "    results = model(frame)[0]\n",
    "\n",
    "    # Annotate detections on the frame\n",
    "    for result in results.boxes.data.tolist():\n",
    "        x1, y1, x2, y2, score, class_id = result\n",
    "        if score > threshold:\n",
    "            cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 4)\n",
    "            label = f\"{results.names[int(class_id)].upper()} {score:.2f}\"\n",
    "            cv2.putText(frame, label, (int(x1), int(y1 - 10)),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1.3, (0, 255, 0), 3, cv2.LINE_AA)\n",
    "\n",
    "    # Save the processed frame to the output video\n",
    "    out.write(frame)\n",
    "\n",
    "    # Optional: Save the frame as an image for debugging\n",
    "    cv2.imwrite(f\"frame_{frame_count}.jpg\", frame)\n",
    "    frame_count += 1\n",
    "\n",
    "    # Optional: Display the frame using matplotlib (alternative to cv2.imshow)\n",
    "    plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "    plt.axis('off')\n",
    "    plt.show(block=False)\n",
    "    plt.pause(0.001)\n",
    "    plt.close()\n",
    "\n",
    "    # Read next frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "# Clean up\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(f\"Processed video saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BylQ-uNOtBFa",
    "outputId": "9fde90db-f8bd-4f28-d863-6b539c362abb"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from ultralytics import YOLO  # or another YOLO module, adjust accordingly\n",
    "\n",
    "# Load the YOLO model\n",
    "model_path = \"license_plate_detector.pt\"  # Replace with your model path\n",
    "model = YOLO(model_path)  # Load the custom model\n",
    "\n",
    "# Initialize the video capture and video writer\n",
    "video_path = 'sample.mp4'  # Input video path\n",
    "output_path = 'sample_output.mp4'  # Output video path\n",
    "cropped_frames_dir = \"cropped_frames\"  # Directory to save cropped images\n",
    "os.makedirs(cropped_frames_dir, exist_ok=True)\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Check if the video was successfully opened\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video.\")\n",
    "    exit()\n",
    "\n",
    "# Get video properties (width, height, fps)\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "# Define codec and create VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec for .mp4\n",
    "out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "# Threshold for object detection\n",
    "threshold = 0.5\n",
    "padding = 20  # Pixels to expand around the bounding box\n",
    "\n",
    "frame_count = 0  # Keep track of frame numbers\n",
    "\n",
    "# Read and process frames from the video\n",
    "ret, frame = cap.read()\n",
    "while ret:\n",
    "    frame_count += 1\n",
    "\n",
    "    # Perform inference\n",
    "    results = model(frame)[0]\n",
    "\n",
    "    # Draw boxes and labels on the frame\n",
    "    for result in results.boxes.data.tolist():\n",
    "        x1, y1, x2, y2, score, class_id = result\n",
    "\n",
    "        if score > threshold:\n",
    "            # Adjust the bounding box to include padding\n",
    "            x1 = max(0, int(x1) - padding)\n",
    "            y1 = max(0, int(y1) - padding)\n",
    "            x2 = min(frame_width, int(x2) + padding)\n",
    "            y2 = min(frame_height, int(y2) + padding)\n",
    "\n",
    "            # Draw enlarged bounding box\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 4)\n",
    "\n",
    "            # Save the cropped region (enlarged area around license plate)\n",
    "            cropped_frame = frame[y1:y2, x1:x2]\n",
    "            cropped_path = f\"{cropped_frames_dir}/cropped_frame_{frame_count}.jpg\"\n",
    "            cv2.imwrite(cropped_path, cropped_frame)\n",
    "\n",
    "            # Put label text\n",
    "            label = f\"{results.names[int(class_id)].upper()} {score:.2f}\"\n",
    "            cv2.putText(frame, label, (x1, y1 - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1.3, (0, 255, 0), 3, cv2.LINE_AA)\n",
    "\n",
    "    # Write the processed frame to the output video\n",
    "    out.write(frame)\n",
    "\n",
    "    # Read next frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "# Release video capture and writer objects\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(f\"Cropped frames saved in: {cropped_frames_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, render_template, request, send_file, redirect, url_for\n",
    "import os\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import zipfile\n",
    "\n",
    "# Initialize Flask app\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Paths\n",
    "UPLOAD_FOLDER = 'uploads'\n",
    "PROCESSED_FOLDER = 'processed'\n",
    "CROPPED_FOLDER = 'processed/cropped_frames'\n",
    "os.makedirs(UPLOAD_FOLDER, exist_ok=True)\n",
    "os.makedirs(PROCESSED_FOLDER, exist_ok=True)\n",
    "os.makedirs(CROPPED_FOLDER, exist_ok=True)\n",
    "\n",
    "# YOLO model\n",
    "MODEL_PATH = \"license_plate_detector.pt\"  # Replace with your YOLO model path\n",
    "model = YOLO(MODEL_PATH)\n",
    "\n",
    "@app.route('/')\n",
    "def home():\n",
    "    return render_template('index.html', section=\"upload\")\n",
    "\n",
    "@app.route('/process', methods=['POST'])\n",
    "def process_video():\n",
    "    if 'video' not in request.files:\n",
    "        return redirect(url_for('home'))\n",
    "\n",
    "    video = request.files['video']\n",
    "    if video.filename == '':\n",
    "        return redirect(url_for('home'))\n",
    "\n",
    "    # Save uploaded video\n",
    "    video_path = os.path.join(UPLOAD_FOLDER, video.filename)\n",
    "    video.save(video_path)\n",
    "\n",
    "    # Process video\n",
    "    processed_video_path = os.path.join(PROCESSED_FOLDER, 'processed_' + video.filename)\n",
    "    process_license_plates(video_path, processed_video_path)\n",
    "\n",
    "    # Create ZIP file of cropped frames\n",
    "    zip_path = os.path.join(PROCESSED_FOLDER, 'cropped_frames.zip')\n",
    "    with zipfile.ZipFile(zip_path, 'w') as zipf:\n",
    "        for root, _, files in os.walk(CROPPED_FOLDER):\n",
    "            for file in files:\n",
    "                zipf.write(os.path.join(root, file), arcname=file)\n",
    "\n",
    "    return render_template('index.html', section=\"result\", video_filename=os.path.basename(processed_video_path), zip_filename='cropped_frames.zip')\n",
    "\n",
    "@app.route('/download/<filename>')\n",
    "def download_file(filename):\n",
    "    file_path = os.path.join(PROCESSED_FOLDER, filename)\n",
    "    return send_file(file_path, as_attachment=True)\n",
    "\n",
    "def process_license_plates(video_path, output_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        raise ValueError(f\"Error: Could not open video file {video_path}.\")\n",
    "\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "    # Define VideoWriter\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "    threshold = 0.5\n",
    "    padding = 20\n",
    "    frame_count = 0\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    while ret:\n",
    "        frame_count += 1\n",
    "\n",
    "        results = model(frame)[0]\n",
    "\n",
    "        for result in results.boxes.data.tolist():\n",
    "            x1, y1, x2, y2, score, class_id = result\n",
    "            if score > threshold:\n",
    "                x1 = max(0, int(x1) - padding)\n",
    "                y1 = max(0, int(y1) - padding)\n",
    "                x2 = min(frame_width, int(x2) + padding)\n",
    "                y2 = min(frame_height, int(y2) + padding)\n",
    "\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 4)\n",
    "                label = f\"{model.names[int(class_id)].upper()} {score:.2f}\"\n",
    "                cv2.putText(frame, label, (x1, y1 - 10),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1.3, (0, 255, 0), 3, cv2.LINE_AA)\n",
    "\n",
    "                # Save cropped frames\n",
    "                cropped_frame = frame[y1:y2, x1:x2]\n",
    "                cropped_path = os.path.join(CROPPED_FOLDER, f\"cropped_frame_{frame_count}.jpg\")\n",
    "                cv2.imwrite(cropped_path, cropped_frame)\n",
    "\n",
    "        out.write(frame)\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
